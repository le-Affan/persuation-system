{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e27425",
   "metadata": {},
   "source": [
    "ADAPTIVE PERSUASION SYSTEM - PRODUCTION VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b07bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required libraries are installed and imported successfully.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers>=4.40.0 huggingface_hub>=0.23.0 torch\n",
    "!pip install -q textblob nltk pandas numpy matplotlib\n",
    "\n",
    "import torch, transformers, textblob, nltk, pandas, numpy, matplotlib\n",
    "print(\"All required libraries are installed and imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d84b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import random\n",
    "\n",
    "from huggingface_hub import InferenceClient, login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "# NLTK Downloads\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69af6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Authentication\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN\n",
    "\n",
    "try:\n",
    "    login(token=HF_TOKEN, add_to_git_credential=False)\n",
    "    print(\"Authenticated\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95269a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load model locally: You are trying to access a gated repo.\n",
      "Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.\n",
      "403 Client Error. (Request ID: Root=1-696264d4-64e04ebe6122323f382652f4;cbdba31c-ed6c-4434-822a-b0e65e5d713e)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.\n",
      "Your request to access model meta-llama/Llama-3.1-8B-Instruct is awaiting a review from the repo authors.\n",
      "Falling back to Inference API until access is approved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the llama 3.1 model\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=HF_TOKEN)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        token=HF_TOKEN,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    print(\"Model loaded successfully!\\n\")\n",
    "    USE_LOCAL_MODEL = True\n",
    "except Exception as e:\n",
    "    print(f\"Could not load model locally: {e}\")\n",
    "    print(\"Falling back to Inference API until access is approved\\n\")\n",
    "    USE_LOCAL_MODEL = False\n",
    "    client = InferenceClient(api_key=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31837e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Campaign ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CAMPAIGN SETUP\n",
    "\n",
    "org_name = input(\"Organization [Children's Education Fund]: \").strip() or \"Children's Education Fund\"\n",
    "cause = input(\"Cause [education for children]: \").strip() or \"providing education to underprivileged children\"\n",
    "amounts = input(\"Amounts [200,500,1000]: \").strip() or \"200, 500, 1000\"\n",
    "impact = input(\"Impact [₹200 = 5 kids supplies]: \").strip() or \"₹200 provides school supplies for 5 children for a month\"\n",
    "\n",
    "DONATION_CONTEXT = {\n",
    "    'organization': org_name,\n",
    "    'cause': cause,\n",
    "    'amounts': amounts,\n",
    "    'impact': impact\n",
    "}\n",
    "\n",
    "print(\"\\nCampaign ready\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b56c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "\n",
    "class Config:\n",
    "    MODEL_NAME = MODEL_NAME\n",
    "    TEMPERATURE = 0.8\n",
    "    MAX_NEW_TOKENS = 64\n",
    "\n",
    "    INITIAL_BELIEF = 0.05\n",
    "    INITIAL_TRUST = 1.0\n",
    "    TRUST_THRESHOLD = 0.5\n",
    "\n",
    "    ALPHA = 0.1\n",
    "    BETA = 0.15\n",
    "    GAMMA = 0.08\n",
    "\n",
    "    HARD_REJECTION_PENALTY = 0.4\n",
    "    SOFT_REJECTION_PENALTY = 0.2\n",
    "    MIN_STRATEGY_WEIGHT = 0.05\n",
    "\n",
    "    MAX_TURNS = 15\n",
    "    MAX_CONSECUTIVE_REJECTIONS = 3\n",
    "\n",
    "    LOG_FILE = \"dialogue_log.jsonl\"\n",
    "    STRATEGIES = [\"Empathy\", \"Impact\", \"SocialProof\", \"Transparency\", \"EthicalUrgency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c13e52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REJECTION DETECTOR\n",
    "\n",
    "class RejectionDetector:\n",
    "\n",
    "    # EXPLICIT NO - very clear rejection\n",
    "    EXPLICIT_PATTERNS = [\n",
    "        r'\\b(no thanks|no thank you|not interested|don\\'t want|won\\'t donate)\\b',\n",
    "        r'\\b(nope|nah|never|absolutely not|definitely not)\\b',\n",
    "        r'\\b(leave me alone|stop asking|not doing|refuse)\\b'\n",
    "    ]\n",
    "\n",
    "    # SOFT NO - hesitation, delay\n",
    "    SOFT_PATTERNS = [\n",
    "        r'\\b(maybe later|not now|not right now|some other time|another time)\\b',\n",
    "        r'\\b(not today|can\\'t right now|busy right now)\\b',\n",
    "        r'\\b(not sure|unsure|uncertain|hesitant|doubtful)\\b',\n",
    "        r'\\b(can\\'t afford|no money|tight budget|broke|expensive)\\b',\n",
    "        r'\\b(i\\'ll think|let me think|need time|consider)\\b'\n",
    "    ]\n",
    "\n",
    "    # TRUST ISSUES\n",
    "    TRUST_PATTERNS = [\n",
    "        r'\\b(pushy|aggressive|pressure|uncomfortable|sketchy|scam|fraud)\\b',\n",
    "        r'\\b(suspicious|don\\'t trust|seems fake|sounds fake)\\b',\n",
    "        r'\\b(why are you|what\\'s your motive|prove it)\\b'\n",
    "    ]\n",
    "\n",
    "    # CURIOSITY - asking questions, wanting info\n",
    "    CURIOSITY_PATTERNS = [\n",
    "        r'\\b(tell me more|tell me about|what about|explain|how does|how do)\\b',\n",
    "        r'\\b(more info|more details|details|information)\\b',\n",
    "        r'\\b(curious|interested in learning|want to know|want to hear)\\b',\n",
    "        r'\\b(what is|who are|where does|when|why)\\b',\n",
    "        r'\\b(can you|could you|would you.*explain|show me)\\b'\n",
    "    ]\n",
    "\n",
    "    # ACTUAL COMMITMENT - very explicit intent to donate\n",
    "    ACCEPTANCE_PATTERNS = [\n",
    "        r'\\b(yes.*i.*donate|i will donate|i\\'ll donate|i want to donate)\\b',\n",
    "        r'\\b(sign me up|count me in|i\\'m in)\\b',\n",
    "        r'\\b(where do i donate|how do i donate|how can i donate)\\b',\n",
    "        r'\\b(i\\'ll give|i will give|i want to give ₹|i can give ₹)\\b',\n",
    "        r'\\b(okay.*donate|ok.*donate|sure.*donate|let\\'s do it)\\b',\n",
    "        r'\\b(take my donation|here\\'s my donation|ready to donate)\\b'\n",
    "    ]\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sentiment = None\n",
    "\n",
    "    def detect(self, user_message: str) -> Dict:\n",
    "        msg = user_message.lower().strip()\n",
    "\n",
    "        # First check: ACTUAL donation commitment\n",
    "        if self._match(msg, self.ACCEPTANCE_PATTERNS):\n",
    "            return {\n",
    "                'rejection_type': 'none',\n",
    "                'rejection_confidence': 0.0,\n",
    "                'trust_concern': False,\n",
    "                'sentiment_score': 0.9,\n",
    "                'sentiment_label': 'positive',\n",
    "                'is_acceptance': True,\n",
    "                'is_curiosity': False\n",
    "            }\n",
    "\n",
    "        # Check curiosity\n",
    "        is_curiosity = self._match(msg, self.CURIOSITY_PATTERNS)\n",
    "\n",
    "        # Check rejection\n",
    "        rejection_type = 'none'\n",
    "        confidence = 0.0\n",
    "\n",
    "        if self._match(msg, self.EXPLICIT_PATTERNS):\n",
    "            rejection_type = 'explicit'\n",
    "            confidence = 0.9\n",
    "        elif self._match(msg, self.SOFT_PATTERNS):\n",
    "            rejection_type = 'soft'\n",
    "            confidence = 0.7\n",
    "\n",
    "        # Trust concerns\n",
    "        trust_concern = self._match(msg, self.TRUST_PATTERNS)\n",
    "\n",
    "        # Sentiment\n",
    "        sent_score, sent_label = self._get_sentiment(user_message)\n",
    "\n",
    "        # Special handling\n",
    "        if is_curiosity and rejection_type == 'none':\n",
    "            rejection_type = 'curiosity'\n",
    "            sent_score = max(0.2, sent_score)\n",
    "\n",
    "        if sent_score < -0.4 and rejection_type == 'none':\n",
    "            rejection_type = 'ambiguous'\n",
    "            confidence = 0.5\n",
    "\n",
    "        if sent_score < -0.6 and rejection_type == 'soft':\n",
    "            rejection_type = 'explicit'\n",
    "            confidence = 0.85\n",
    "\n",
    "        return {\n",
    "            'rejection_type': rejection_type,\n",
    "            'rejection_confidence': confidence,\n",
    "            'trust_concern': trust_concern,\n",
    "            'sentiment_score': sent_score,\n",
    "            'sentiment_label': sent_label,\n",
    "            'is_acceptance': False,\n",
    "            'is_curiosity': is_curiosity\n",
    "        }\n",
    "\n",
    "\n",
    "    def _match(self, text: str, patterns: List[str]) -> bool:\n",
    "        return any(re.search(p, text, re.IGNORECASE) for p in patterns)\n",
    "\n",
    "    def _get_sentiment(self, text: str) -> Tuple[float, str]:\n",
    "        try:\n",
    "            if self.sentiment:\n",
    "                r = self.sentiment(text[:512])[0]\n",
    "                score = r['score'] if r['label'] == 'POSITIVE' else -r['score']\n",
    "                return score, r['label'].lower()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        blob = TextBlob(text)\n",
    "        pol = blob.sentiment.polarity\n",
    "        label = 'positive' if pol > 0 else ('negative' if pol < 0 else 'neutral')\n",
    "        return pol, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b546411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
